{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotheken/Einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beobachtung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Zeilen anpassen (durchschnitt, vorheriger Wert) oder löschen\n",
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train.Solar_MWh.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ref_datetime', 'valid_time', 'SolarDownwardRadiation', 'CloudCover',\n",
       "       'Temperature', 'Weather Model', 'valid_datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[df_forecasts.SolarDownwardRadiation.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit NaN-Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Umgang mit NaN-Werten in df_train__\n",
    "- Betroffene Zeilen 4 von 19968 (ca.0,02%)\n",
    "- Mein Ansatz: Zeilen, wo bei `Solar_MWh` NaN auftaucht, löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Umgang mit NaN-Werten in df_forecasts**\n",
    "- Betroffene Zeilen: max. 1226 von 606797 (ca. 0,2%)\n",
    "- Mein Ansatz: Daten behalten und Auffüllen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spalte SolarDownwardRadiation\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "\n",
    "# # Spalte CloudCover\n",
    "# df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "\n",
    "# # Spalte Temperature\n",
    "# df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts = df_forecasts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validierung nach der Bereinigung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN-Werte in df_train:\", df_train.isna().sum())\n",
    "print(\"NaN-Werte in df_forecasts:\", df_forecasts.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test1.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit Negativen Werten `SolarDownwardRadiation` (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative SolarDownwardRadiation anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 Untersuchung der Energiedaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wie viele Datenpunkte, die vorhergesagt werden sollen, gibt es in den Trainings- bzw. Testdaten?\n",
    "train_points = len(df_train)\n",
    "\n",
    "# Anzahl der Datenpunkte in den beiden Testsets\n",
    "test1_points = len(df_test1)\n",
    "test2_points = len(df_test2)\n",
    "\n",
    "print(f\"Trainingsdatenpunkte: {train_points}\")\n",
    "print(f\"Testdatenpunkte - Test1: {test1_points}, Test2: {test2_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tagesverlauf visualisieren\n",
    "# (Zufälige)Geburtstage auswählen, bzw. Frühlings-, Sommer- und Winterzeit\n",
    "birthdates = [\"2022-05-21\", \"2022-07-28\", \"2022-12-16\"]\n",
    "birthdates = pd.to_datetime(birthdates) # Strings in datetime umwandeln\n",
    "\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"dtm\"]).dt.date  # Extrahiere das Datum\n",
    "\n",
    "# Filter für die ausgewählten Tage\n",
    "filtered_data = df_train[df_train[\"date\"].isin(birthdates.date)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for date in birthdates:\n",
    "    daily_data = filtered_data[filtered_data[\"date\"] == date.date()]\n",
    "    plt.plot(\n",
    "        pd.to_datetime(daily_data[\"dtm\"]).dt.hour,\n",
    "        daily_data[\"Solar_MWh\"],\n",
    "        label=str(date.date())\n",
    "    )\n",
    "plt.xlabel(\"Stunde des Tages\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Tagesverlauf der Stromerzeugung\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-05-21  Frühling <br>\n",
    "2022-07-28 -> Sommer <br>\n",
    "2022-12-16 -> Winter <br>\n",
    "Man erkennt deutlich, dass logischerweise Nachts kein Strom produziert wird und der Tag der wichtige Teil für die Stromerzeugung. Auch erkennbar ist, dass der Winter weniger Strom produziert, was sehr stark an der Wolkenbedeckung liegen kann und die Tageszeit kürzer anhält als Frühling und Sommer.\n",
    "Einen kleinen Ausreißer erkennt man beim Frühling, was bei ca. 10-12Uhr kurz wenig Strom produziert. Das könnte an einem Regenschauer liegen oder anderen technischen Fehlern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gesamtverlauf visualisieren\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pd.to_datetime(df_train[\"dtm\"]), df_train[\"Solar_MWh\"], color=\"blue\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Gesamtverlauf der Stromerzeugung (Trainingsdaten)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Sommer steigt die Stromerzeugung, da es länger hell bleibt und wenig Wolkenbedeckung hat. <br>\n",
    "Im Winter sinkt die Stromerzeugung, da es schneller dunkel wird und weniger Sonnenschein tagsüber hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2 Merge und Untersuchung von Zusammenhänge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge mit Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test1 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test2 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineered Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot erstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Plot erstellen\n",
    "# Scatterplots für jede Wettervariable vs. Solar_MWh\n",
    "weather_attributes = [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, attr in enumerate(weather_attributes):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.scatterplot(data=df_merged, x=attr, y=\"Solar_MWh\", alpha=0.5)\n",
    "    plt.title(f\"{attr} vs Solar_MWh\")\n",
    "    plt.xlabel(attr)\n",
    "    plt.ylabel(\"Solar_MWh\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Erkennung von Zusammenhängen\n",
    "# Korrelationen zwischen Wetterattributen und Solar_MWh berechnen\n",
    "correlations = df_merged[weather_attributes + [\"Solar_MWh\"]].corr()[\"Solar_MWh\"].sort_values(ascending=False)\n",
    "print(\"Korrelationen mit Solar_MWh:\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wolkenbedeckung weißt auf einen schwachen Zusammenhang zur Stromerzeugung, während die Sonneneinstrahlung wichtiger ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3 Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behandlung von Ausreißern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung von Solar_MWh\n",
    "sns.histplot(df_train[\"Solar_MWh\"], kde=True, bins=30)\n",
    "plt.title(\"Train - Verteilung von Solar_MWh\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot zur Erkennung von Ausreißern\n",
    "sns.boxplot(x=df_train[\"Solar_MWh\"])\n",
    "plt.title(\"Train - Boxplot von Solar_MWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Es wäre für mich eine logische Entscheidung die Ausreißer 0 mitzunehmen ins Modell, weil diese möglicherweise echte Werte sind. Das liegt daran, das Nachts keine Stromproduktion stattfindet, sowie im Winter die Nacht länger andauert. <br>\n",
    "Zusätzlich ist es tagsüber deutlich inkonsistenter, da verschiedene Feature (Sonnenstrahlung, Wolkenbedeckung, Temperatur) Einfluss auf die die Stromproduktion nehmen.\n",
    "\n",
    "Zusammengefasst entscheide ich mich die Ausreißer nicht rauszunehmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorverarbeitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung = ColumnTransformer([\n",
    "    (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"Weather Model\"]),\n",
    "    (\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\" ]),\n",
    "    (\"Skalieren\", StandardScaler(), [\"Solar_capacity_mwp\", \"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Entfernen von Spalten\", \"drop\", [\"dtm\", \"ref_datetime\", \"valid_time\", \"valid_datetime\"])\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vorverarbeitung.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4 Generierung von neuen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitbasierte Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tageszeit\n",
    "df_merged[\"hour\"] = df_merged[\"dtm\"].dt.hour\n",
    "# Monat oder Saison\n",
    "df_merged[\"month\"] = df_merged[\"dtm\"].dt.month\n",
    "df_merged[\"season\"] = df_merged[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"lag_1\"] = df_merged[\"Solar_MWh\"].shift(1)\n",
    "df_merged[\"lag_24\"] = df_merged[\"Solar_MWh\"].shift(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Features (Gleitender Durchschnitt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"rolling_mean_24\"] = df_merged[\"Solar_MWh\"].rolling(window=24).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktion von Wetter und Zeit\n",
    "- temp_radiation_interaction: Produkt von Temperatur und Sonneneinstrahlung\n",
    "- cloud_hour_interaction: Produkt von CloudCover und Stunde des Tages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"temp_radiation_interaction\"] = (\n",
    "    df_merged[\"Temperature\"] * df_merged[\"SolarDownwardRadiation\"]\n",
    ")\n",
    "df_merged[\"cloud_hour_interaction\"] = (\n",
    "    df_merged[\"CloudCover\"] * df_merged[\"hour\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Merkmale\n",
    "Verhältnis von erzeugtem Strom zur verfügbaren Kapazität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"solar_efficiency\"] = df_merged[\"Solar_MWh\"] / df_merged[\"Solar_capacity_mwp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation von Wetterattributen:\n",
    "- scaled_temperature: Skaliere Temperatur auf den Bereich [0, 1].\n",
    "- adjusted_radiation: Negative Werte auf 0 setzen (falls noch nicht gemacht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_merged[\"scaled_temperature\"] = scaler.fit_transform(\n",
    "    df_merged[[\"Temperature\"]]\n",
    ")\n",
    "df_merged[\"adjusted_radiation\"] = df_merged[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 5 Modell trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung), (\"Linear-Model Training\", LinearRegression())])\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung von Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "ridge = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (Ridge):\", ridge.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Ridge):\", -ridge.best_score_)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = GridSearchCV(Lasso(max_iter=10000), param_grid, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"Best alpha (Lasso):\", lasso.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Lasso):\", -lasso.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 2: Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Best params (Decision Tree):\", tree.best_params_)\n",
    "print(\"Best RMSE (Decision Tree):\", -tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 3: Ensemble-Modell (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "forest = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Best params (Random Forest):\", forest.best_params_)\n",
    "print(\"Best RMSE (Random Forest):\", -forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wichtigste Features bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Linear\n",
    "linear_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": pipe_linear.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", linear_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Ridge\n",
    "ridge_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": ridge.best_estimator_.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", ridge_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Random Forest\n",
    "forest_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    #\"Importance\": forest.best_estimator_.feature_importances_\n",
    "})#.sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Random Forest Feature Importance:\\n\", forest_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfassung | Wenig Zellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5 | 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful testing Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtm</th>\n",
       "      <th>ref_datetime</th>\n",
       "      <th>Solar_capacity_mwp</th>\n",
       "      <th>Solar_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dtm, ref_datetime, Solar_capacity_mwp, Solar_MWh]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammengefassetes Modelltraining ohne zusätzliche Zellen\n",
    "# ? Kommentare sind gehighlighted mit der \"Better Comments\" Extension\n",
    "# * Bibliotheken laden und Daten einlesen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von NaN-Werten \n",
    "# TODO Statt .dropna() eine Imputation einsetzen\n",
    "# ? Beim Forecast kann es ignoriert werden, da es im Transformer verwendet wird (aber erst im nach dem Merge)\n",
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.fillna(0)\n",
    "# df_forecasts = df_forecasts.dropna()\n",
    "# Spalte SolarDownwardRadiation\n",
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "# Spalte CloudCover\n",
    "df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "# Spalte Temperature\n",
    "df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von Negativen Werten\n",
    "# TODO Kann auch ignoriert werden\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Merge von Test-/Trainingsdaten mit Forecast-Dataset\n",
    "# TODO Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vom fehlerhaften Merge\n",
    "# // df_merged = df_merged.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test1 = df_merged_test1.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test2 = df_merged_test2.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering und Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeitbasiert Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für zyklische Transformation | Abruf im ColumnTransformer\n",
    "def cyclical_features(X):\n",
    "    X = X.copy()\n",
    "    X[\"hour_sin\"] = np.sin(2 * np.pi * X[\"hour\"] / 24)\n",
    "    X[\"hour_cos\"] = np.cos(2 * np.pi * X[\"hour\"] / 24)\n",
    "    return X[[\"hour_sin\", \"hour_cos\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode zur Bestimmung des Zeitraums\n",
    "def assign_time_period(hour):\n",
    "    if 5 <= hour < 9:\n",
    "        return 'Morgen'\n",
    "    elif 9 <= hour < 12:\n",
    "        return 'Vormittag'\n",
    "    elif 12 <= hour < 15:\n",
    "        return 'Mittag'\n",
    "    elif 15 <= hour < 18:\n",
    "        return 'Nachmittag'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Abend'\n",
    "    else:\n",
    "        return 'Nacht'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_time in merged_list:  \n",
    "    # Tageszeit\n",
    "    add_time[\"hour\"] = add_time[\"dtm\"].dt.hour\n",
    "    add_time[\"time_period\"] = add_time[\"hour\"].apply(assign_time_period)\n",
    "    # add_time[\"day_of_week\"] = add_time[\"dtm\"].dt.day_of_week\n",
    "    # Monat oder Saison\n",
    "    add_time[\"month\"] = add_time[\"dtm\"].dt.month\n",
    "    add_time[\"season\"] = add_time[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wetterbasierte Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_temperature_level(temperature):\n",
    "    if temperature < 0:\n",
    "        return 'Sehr kalt'\n",
    "    elif 0 <= temperature < 10:\n",
    "        return 'Kalt'\n",
    "    elif 10 <= temperature < 15:\n",
    "        return 'Kühl'\n",
    "    elif 15 <= temperature < 20:\n",
    "        return 'Mild'\n",
    "    elif 20 <= temperature < 25:\n",
    "        return 'Warm'\n",
    "    elif 25 <= temperature < 30:\n",
    "        return 'Sehr warm'\n",
    "    elif 30 <= temperature < 35:\n",
    "        return 'Heiß'\n",
    "    else:\n",
    "        return 'Sehr heiß'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Interaktion zwischen Sonneneinstrahlung und Temperatur: Hohe Temperaturen können die Effizienz von Solaranlagen reduzieren, trotz hoher Sonneneinstrahlung\n",
    "    add_weather[\"Sun_CloudCover\"] = add_weather[\"Temperature\"] * add_weather[\"SolarDownwardRadiation\"]\n",
    "    # Bewölkerungsdynamik\n",
    "    add_weather[\"CloudCover_change\"] = add_weather[\"CloudCover\"].diff()\n",
    "    add_weather[\"Temperature_Level\"] = add_weather[\"Temperature\"].apply(assign_temperature_level)\n",
    "    \n",
    "df_merged = df_merged.fillna(0)\n",
    "df_merged_test1 = df_merged_test1.fillna(0)\n",
    "df_merged_test2 = df_merged_test2.fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historische Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Rolling Average für Sonneneinstrahlung (z. B. über die letzten 3 Stunden)\n",
    "    # add_weather['AvgSolarRadiation_last_3h'] = add_weather['SolarDownwardRadiation'].rolling(window=3).mean()\n",
    "    # # Lag-Feature: Sonneneinstrahlung der letzten Stunde\n",
    "    add_weather['SolarRadiation_lag_1h'] = add_weather['SolarDownwardRadiation'].shift(1)\n",
    "    # # Lag-Feature: Temperatur der letzten Stunde\n",
    "    # add_weather['Temperature_lag_1h'] = add_weather['Temperature'].shift(1)\n",
    "    \n",
    "df_merged = df_merged.fillna(0)\n",
    "df_merged_test1 = df_merged_test1.fillna(0)\n",
    "df_merged_test2 = df_merged_test2.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# * Daten aufteilen\n",
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# * Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Vorverarbeitung: Transformer\n",
    "vorverarbeitung = ColumnTransformer([\n",
    "    (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"Weather Model\", \"time_period\", \"season\", \"Temperature_Level\"]),\n",
    "    (\"Zyklisch_hour\", FunctionTransformer(cyclical_features), [\"hour\"]),\n",
    "    #(\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Skalieren\", StandardScaler(), [\n",
    "        \"SolarDownwardRadiation\", \"Sun_CloudCover\", \"CloudCover_change\", \"SolarRadiation_lag_1h\"\n",
    "        ]),\n",
    "    (\"drop_columns\", 'drop', [\"dtm\", \"valid_time\", \"valid_datetime\", \"Solar_capacity_mwp\", \"ref_datetime\", \"hour\", \"month\", \"CloudCover\", \"Temperature\"])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN-Werte: dtm                          0\n",
      "ref_datetime                 0\n",
      "Solar_capacity_mwp           0\n",
      "valid_time                   0\n",
      "SolarDownwardRadiation       0\n",
      "CloudCover                   0\n",
      "Temperature                  0\n",
      "Weather Model                0\n",
      "valid_datetime               0\n",
      "hour                         0\n",
      "time_period                  0\n",
      "month                        0\n",
      "season                       0\n",
      "Sun_CloudCover               0\n",
      "CloudCover_change            0\n",
      "AvgSolarRadiation_last_3h    0\n",
      "SolarRadiation_lag_1h        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN-Werte:\", X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lineares Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'fit_intercept': False}\n",
      "RMSE: 57.38255073061118\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lineares Modell\n",
    "# * Hyperparametersuche\n",
    "param_grid = {\"fit_intercept\": [True, False]}\n",
    "\n",
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                        (\"gs_linear\", GridSearchCV(LinearRegression(), param_grid, cv=5))\n",
    "                         ])\n",
    "\n",
    "# Trainiere Lineares Modell\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_linear.named_steps[\"gs_linear\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "# RMSE\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Vorhersage für Testdaten 1 und 2\n",
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_linear.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(57.38255073061118)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer Zyklisch_hour (type FunctionTransformer) does not provide get_feature_names_out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m best_linear_model \u001b[38;5;241m=\u001b[39m pipe_linear\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs_linear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Abrufe der Feature-Namen nach Vorverarbeitung\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m pipe_linear\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVorverarbeitung\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Erstelle einen DataFrame mit den Koeffizienten\u001b[39;00m\n\u001b[0;32m      8\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature_names,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_linear_model\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     11\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\achim\\anaconda3\\envs\\dsc4\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:630\u001b[0m, in \u001b[0;36mColumnTransformer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    623\u001b[0m transformer_with_feature_names_out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, trans, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    625\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     skip_empty_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    628\u001b[0m     skip_drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    629\u001b[0m ):\n\u001b[1;32m--> 630\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_feature_name_out_for_transformer(\n\u001b[0;32m    631\u001b[0m         name, trans, input_features\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\achim\\anaconda3\\envs\\dsc4\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:593\u001b[0m, in \u001b[0;36mColumnTransformer._get_feature_name_out_for_transformer\u001b[1;34m(self, name, trans, feature_names_in)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# An actual transformer\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trans, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    594\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(trans)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot provide get_feature_names_out.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m     )\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mget_feature_names_out(names)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Transformer Zyklisch_hour (type FunctionTransformer) does not provide get_feature_names_out."
     ]
    }
   ],
   "source": [
    "\n",
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_linear_model = pipe_linear.named_steps[\"gs_linear\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_linear.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_linear_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs().round(1)\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.05, 0.1, 0.5, 1, 10, 20, 40, 80, 100, 125, 200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 1}\n",
      "RMSE: 58.4996850092601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_21264\\3921426539.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_21264\\3921426539.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test2[\"Solar_MWh_pred\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Ridge Modell\n",
    "pipe_ridge = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_ridge\", GridSearchCV(Ridge(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_ridge.named_steps[\"gs_ridge\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_ridge.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_ridge.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_ridge.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(58.4996850092601)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>103.291188</td>\n",
       "      <td>103.291188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skalieren__SolarRadiation_lag_1h</td>\n",
       "      <td>65.101986</td>\n",
       "      <td>65.101986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__time_period_Vormittag</td>\n",
       "      <td>46.575643</td>\n",
       "      <td>46.575643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__time_period_Nachmittag</td>\n",
       "      <td>-31.374148</td>\n",
       "      <td>31.374148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__time_period_Mittag</td>\n",
       "      <td>22.352317</td>\n",
       "      <td>22.352317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__time_period_Abend</td>\n",
       "      <td>-16.905081</td>\n",
       "      <td>16.905081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__time_period_Nacht</td>\n",
       "      <td>-10.621326</td>\n",
       "      <td>10.621326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__time_period_Morgen</td>\n",
       "      <td>-10.027404</td>\n",
       "      <td>10.027404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__season_3</td>\n",
       "      <td>-9.878982</td>\n",
       "      <td>9.878982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__season_4</td>\n",
       "      <td>5.189995</td>\n",
       "      <td>5.189995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__season_1</td>\n",
       "      <td>3.169264</td>\n",
       "      <td>3.169264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skalieren__CloudCover_change</td>\n",
       "      <td>2.046379</td>\n",
       "      <td>2.046379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-1.966865</td>\n",
       "      <td>1.966865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>1.966865</td>\n",
       "      <td>1.966865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__season_2</td>\n",
       "      <td>1.519724</td>\n",
       "      <td>1.519724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skalieren__Sun_CloudCover</td>\n",
       "      <td>-1.298798</td>\n",
       "      <td>1.298798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Coefficient  Feature_Importance\n",
       "12     Skalieren__SolarDownwardRadiation   103.291188          103.291188\n",
       "15      Skalieren__SolarRadiation_lag_1h    65.101986           65.101986\n",
       "7    O-H-Encoding__time_period_Vormittag    46.575643           46.575643\n",
       "5   O-H-Encoding__time_period_Nachmittag   -31.374148           31.374148\n",
       "3       O-H-Encoding__time_period_Mittag    22.352317           22.352317\n",
       "2        O-H-Encoding__time_period_Abend   -16.905081           16.905081\n",
       "6        O-H-Encoding__time_period_Nacht   -10.621326           10.621326\n",
       "4       O-H-Encoding__time_period_Morgen   -10.027404           10.027404\n",
       "10                O-H-Encoding__season_3    -9.878982            9.878982\n",
       "11                O-H-Encoding__season_4     5.189995            5.189995\n",
       "8                 O-H-Encoding__season_1     3.169264            3.169264\n",
       "14          Skalieren__CloudCover_change     2.046379            2.046379\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS    -1.966865            1.966865\n",
       "0   O-H-Encoding__Weather Model_DWD ICON     1.966865            1.966865\n",
       "9                 O-H-Encoding__season_2     1.519724            1.519724\n",
       "13             Skalieren__Sun_CloudCover    -1.298798            1.298798"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_ridge_model = pipe_ridge.named_steps[\"gs_ridge\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_ridge.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_ridge_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 0.01}\n",
      "RMSE: 58.50693605461164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_21264\\466459414.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_21264\\466459414.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test2[\"Solar_MWh_pred\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lasso Modell\n",
    "pipe_lasso = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_lasso\", GridSearchCV(Lasso(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_lasso.named_steps[\"gs_lasso\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_lasso.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_lasso.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_lasso.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(58.50693605461164)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>1.208729e+02</td>\n",
       "      <td>1.208729e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skalieren__SolarRadiation_lag_1h</td>\n",
       "      <td>7.825981e+01</td>\n",
       "      <td>7.825981e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__time_period_Vormittag</td>\n",
       "      <td>5.539818e+01</td>\n",
       "      <td>5.539818e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__time_period_Mittag</td>\n",
       "      <td>3.590930e+01</td>\n",
       "      <td>3.590930e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skalieren__AvgSolarRadiation_last_3h</td>\n",
       "      <td>-3.126565e+01</td>\n",
       "      <td>3.126565e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__time_period_Nachmittag</td>\n",
       "      <td>-1.668769e+01</td>\n",
       "      <td>1.668769e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__season_3</td>\n",
       "      <td>-1.170344e+01</td>\n",
       "      <td>1.170344e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__time_period_Abend</td>\n",
       "      <td>-5.448076e+00</td>\n",
       "      <td>5.448076e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>3.087895e+00</td>\n",
       "      <td>3.087895e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__season_4</td>\n",
       "      <td>2.677540e+00</td>\n",
       "      <td>2.677540e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skalieren__CloudCover_change</td>\n",
       "      <td>1.989835e+00</td>\n",
       "      <td>1.989835e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__season_1</td>\n",
       "      <td>9.560960e-01</td>\n",
       "      <td>9.560960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__time_period_Morgen</td>\n",
       "      <td>-8.065198e-01</td>\n",
       "      <td>8.065198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skalieren__Sun_CloudCover</td>\n",
       "      <td>-7.296114e-01</td>\n",
       "      <td>7.296114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__season_2</td>\n",
       "      <td>-1.819113e-01</td>\n",
       "      <td>1.819113e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-1.437128e-16</td>\n",
       "      <td>1.437128e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__time_period_Nacht</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature   Coefficient  Feature_Importance\n",
       "12     Skalieren__SolarDownwardRadiation  1.208729e+02        1.208729e+02\n",
       "15      Skalieren__SolarRadiation_lag_1h  7.825981e+01        7.825981e+01\n",
       "7    O-H-Encoding__time_period_Vormittag  5.539818e+01        5.539818e+01\n",
       "3       O-H-Encoding__time_period_Mittag  3.590930e+01        3.590930e+01\n",
       "16  Skalieren__AvgSolarRadiation_last_3h -3.126565e+01        3.126565e+01\n",
       "5   O-H-Encoding__time_period_Nachmittag -1.668769e+01        1.668769e+01\n",
       "10                O-H-Encoding__season_3 -1.170344e+01        1.170344e+01\n",
       "2        O-H-Encoding__time_period_Abend -5.448076e+00        5.448076e+00\n",
       "0   O-H-Encoding__Weather Model_DWD ICON  3.087895e+00        3.087895e+00\n",
       "11                O-H-Encoding__season_4  2.677540e+00        2.677540e+00\n",
       "14          Skalieren__CloudCover_change  1.989835e+00        1.989835e+00\n",
       "8                 O-H-Encoding__season_1  9.560960e-01        9.560960e-01\n",
       "4       O-H-Encoding__time_period_Morgen -8.065198e-01        8.065198e-01\n",
       "13             Skalieren__Sun_CloudCover -7.296114e-01        7.296114e-01\n",
       "9                 O-H-Encoding__season_2 -1.819113e-01        1.819113e-01\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS -1.437128e-16        1.437128e-16\n",
       "6        O-H-Encoding__time_period_Nacht  0.000000e+00        0.000000e+00"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_lasso_model = pipe_lasso.named_steps[\"gs_lasso\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_lasso.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_lasso_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 5, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
      "RMSE: 54.89852266685542\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: DecisionTree Modell\n",
    "pipe_tree = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_tree\", GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_tree.named_steps[\"gs_tree\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_tree.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_tree.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_tree.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(54.89852266685542)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>0.819577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skalieren__AvgSolarRadiation_last_3h</td>\n",
       "      <td>0.117158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skalieren__SolarRadiation_lag_1h</td>\n",
       "      <td>0.033221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__time_period_Nachmittag</td>\n",
       "      <td>0.006381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__time_period_Vormittag</td>\n",
       "      <td>0.005624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skalieren__Sun_CloudCover</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skalieren__CloudCover_change</td>\n",
       "      <td>0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__time_period_Mittag</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__season_1</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__season_3</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__time_period_Morgen</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__time_period_Abend</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__season_4</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__season_2</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__time_period_Nacht</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Importance\n",
       "12     Skalieren__SolarDownwardRadiation    0.819577\n",
       "16  Skalieren__AvgSolarRadiation_last_3h    0.117158\n",
       "15      Skalieren__SolarRadiation_lag_1h    0.033221\n",
       "5   O-H-Encoding__time_period_Nachmittag    0.006381\n",
       "7    O-H-Encoding__time_period_Vormittag    0.005624\n",
       "13             Skalieren__Sun_CloudCover    0.004533\n",
       "14          Skalieren__CloudCover_change    0.003790\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS    0.003241\n",
       "3       O-H-Encoding__time_period_Mittag    0.001616\n",
       "8                 O-H-Encoding__season_1    0.001535\n",
       "10                O-H-Encoding__season_3    0.001166\n",
       "4       O-H-Encoding__time_period_Morgen    0.000693\n",
       "2        O-H-Encoding__time_period_Abend    0.000456\n",
       "11                O-H-Encoding__season_4    0.000432\n",
       "0   O-H-Encoding__Weather Model_DWD ICON    0.000293\n",
       "9                 O-H-Encoding__season_2    0.000276\n",
       "6        O-H-Encoding__time_period_Nacht    0.000007"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_tree_model = pipe_tree.named_steps[\"gs_tree\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_tree.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_tree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 25}\n",
      "RMSE: 50.465222223505016\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "# !Pipeline: Random Forest Modell\n",
    "pipe_rand_frst = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_rand_frst\", GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_rand_frst.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(50.496053918857356)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>0.812659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skalieren__AvgSolarRadiation_last_3h</td>\n",
       "      <td>0.120524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skalieren__SolarRadiation_lag_1h</td>\n",
       "      <td>0.034452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__time_period_Nachmittag</td>\n",
       "      <td>0.006365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__time_period_Vormittag</td>\n",
       "      <td>0.006199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skalieren__Sun_CloudCover</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skalieren__CloudCover_change</td>\n",
       "      <td>0.004979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__time_period_Mittag</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__season_3</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__season_1</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__time_period_Morgen</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__time_period_Abend</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__season_2</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__season_4</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__time_period_Nacht</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Importance\n",
       "12     Skalieren__SolarDownwardRadiation    0.812659\n",
       "16  Skalieren__AvgSolarRadiation_last_3h    0.120524\n",
       "15      Skalieren__SolarRadiation_lag_1h    0.034452\n",
       "5   O-H-Encoding__time_period_Nachmittag    0.006365\n",
       "7    O-H-Encoding__time_period_Vormittag    0.006199\n",
       "13             Skalieren__Sun_CloudCover    0.005338\n",
       "14          Skalieren__CloudCover_change    0.004979\n",
       "3       O-H-Encoding__time_period_Mittag    0.001910\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS    0.001623\n",
       "10                O-H-Encoding__season_3    0.001500\n",
       "8                 O-H-Encoding__season_1    0.001358\n",
       "0   O-H-Encoding__Weather Model_DWD ICON    0.001321\n",
       "4       O-H-Encoding__time_period_Morgen    0.000505\n",
       "2        O-H-Encoding__time_period_Abend    0.000488\n",
       "9                 O-H-Encoding__season_2    0.000399\n",
       "11                O-H-Encoding__season_4    0.000375\n",
       "6        O-H-Encoding__time_period_Nacht    0.000004"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_randtree_model = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_rand_frst.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_randtree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "RMSE: 50.74023095252428\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter für Gradient Boosting\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "# !Pipeline: Gradient Boosting Modell\n",
    "pipe_grad_boost = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_grad_boost\", GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid))\n",
    "                       ])\n",
    "pipe_grad_boost.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_grad_boost.named_steps[\"gs_grad_boost\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_grad_boost.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_grad_boost.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_grad_boost.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(50.74023095252428)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
