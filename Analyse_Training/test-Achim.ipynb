{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotheken/Einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beobachtung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Zeilen anpassen (durchschnitt, vorheriger Wert) oder löschen\n",
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train.Solar_MWh.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[df_forecasts.SolarDownwardRadiation.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit NaN-Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Umgang mit NaN-Werten in df_train__\n",
    "- Betroffene Zeilen 4 von 19968 (ca.0,02%)\n",
    "- Mein Ansatz: Zeilen, wo bei `Solar_MWh` NaN auftaucht, löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Umgang mit NaN-Werten in df_forecasts**\n",
    "- Betroffene Zeilen: max. 1226 von 606797 (ca. 0,2%)\n",
    "- Mein Ansatz: Daten behalten und Auffüllen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spalte SolarDownwardRadiation\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "\n",
    "# # Spalte CloudCover\n",
    "# df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "\n",
    "# # Spalte Temperature\n",
    "# df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts = df_forecasts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validierung nach der Bereinigung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN-Werte in df_train:\", df_train.isna().sum())\n",
    "print(\"NaN-Werte in df_forecasts:\", df_forecasts.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test1.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit Negativen Werten `SolarDownwardRadiation` (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative SolarDownwardRadiation anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 Untersuchung der Energiedaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wie viele Datenpunkte, die vorhergesagt werden sollen, gibt es in den Trainings- bzw. Testdaten?\n",
    "train_points = len(df_train)\n",
    "\n",
    "# Anzahl der Datenpunkte in den beiden Testsets\n",
    "test1_points = len(df_test1)\n",
    "test2_points = len(df_test2)\n",
    "\n",
    "print(f\"Trainingsdatenpunkte: {train_points}\")\n",
    "print(f\"Testdatenpunkte - Test1: {test1_points}, Test2: {test2_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tagesverlauf visualisieren\n",
    "# (Zufälige)Geburtstage auswählen, bzw. Frühlings-, Sommer- und Winterzeit\n",
    "birthdates = [\"2022-05-21\", \"2022-07-28\", \"2022-12-16\"]\n",
    "birthdates = pd.to_datetime(birthdates) # Strings in datetime umwandeln\n",
    "\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"dtm\"]).dt.date  # Extrahiere das Datum\n",
    "\n",
    "# Filter für die ausgewählten Tage\n",
    "filtered_data = df_train[df_train[\"date\"].isin(birthdates.date)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for date in birthdates:\n",
    "    daily_data = filtered_data[filtered_data[\"date\"] == date.date()]\n",
    "    plt.plot(\n",
    "        pd.to_datetime(daily_data[\"dtm\"]).dt.hour,\n",
    "        daily_data[\"Solar_MWh\"],\n",
    "        label=str(date.date())\n",
    "    )\n",
    "plt.xlabel(\"Stunde des Tages\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Tagesverlauf der Stromerzeugung\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-05-21  Frühling <br>\n",
    "2022-07-28 -> Sommer <br>\n",
    "2022-12-16 -> Winter <br>\n",
    "Man erkennt deutlich, dass logischerweise Nachts kein Strom produziert wird und der Tag der wichtige Teil für die Stromerzeugung. Auch erkennbar ist, dass der Winter weniger Strom produziert, was sehr stark an der Wolkenbedeckung liegen kann und die Tageszeit kürzer anhält als Frühling und Sommer.\n",
    "Einen kleinen Ausreißer erkennt man beim Frühling, was bei ca. 10-12Uhr kurz wenig Strom produziert. Das könnte an einem Regenschauer liegen oder anderen technischen Fehlern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gesamtverlauf visualisieren\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pd.to_datetime(df_train[\"dtm\"]), df_train[\"Solar_MWh\"], color=\"blue\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Gesamtverlauf der Stromerzeugung (Trainingsdaten)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Sommer steigt die Stromerzeugung, da es länger hell bleibt und wenig Wolkenbedeckung hat. <br>\n",
    "Im Winter sinkt die Stromerzeugung, da es schneller dunkel wird und weniger Sonnenschein tagsüber hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2 Merge und Untersuchung von Zusammenhänge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge mit Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test1 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test2 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineered Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot erstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Plot erstellen\n",
    "# Scatterplots für jede Wettervariable vs. Solar_MWh\n",
    "weather_attributes = [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, attr in enumerate(weather_attributes):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.scatterplot(data=df_merged, x=attr, y=\"Solar_MWh\", alpha=0.5)\n",
    "    plt.title(f\"{attr} vs Solar_MWh\")\n",
    "    plt.xlabel(attr)\n",
    "    plt.ylabel(\"Solar_MWh\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Erkennung von Zusammenhängen\n",
    "# Korrelationen zwischen Wetterattributen und Solar_MWh berechnen\n",
    "correlations = df_merged[weather_attributes + [\"Solar_MWh\"]].corr()[\"Solar_MWh\"].sort_values(ascending=False)\n",
    "print(\"Korrelationen mit Solar_MWh:\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wolkenbedeckung weißt auf einen schwachen Zusammenhang zur Stromerzeugung, während die Sonneneinstrahlung wichtiger ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3 Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behandlung von Ausreißern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung von Solar_MWh\n",
    "sns.histplot(df_train[\"Solar_MWh\"], kde=True, bins=30)\n",
    "plt.title(\"Train - Verteilung von Solar_MWh\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot zur Erkennung von Ausreißern\n",
    "sns.boxplot(x=df_train[\"Solar_MWh\"])\n",
    "plt.title(\"Train - Boxplot von Solar_MWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Es wäre für mich eine logische Entscheidung die Ausreißer 0 mitzunehmen ins Modell, weil diese möglicherweise echte Werte sind. Das liegt daran, das Nachts keine Stromproduktion stattfindet, sowie im Winter die Nacht länger andauert. <br>\n",
    "Zusätzlich ist es tagsüber deutlich inkonsistenter, da verschiedene Feature (Sonnenstrahlung, Wolkenbedeckung, Temperatur) Einfluss auf die die Stromproduktion nehmen.\n",
    "\n",
    "Zusammengefasst entscheide ich mich die Ausreißer nicht rauszunehmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorverarbeitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung = ColumnTransformer([\n",
    "    (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"Weather Model\"]),\n",
    "    (\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\" ]),\n",
    "    (\"Skalieren\", StandardScaler(), [\"Solar_capacity_mwp\", \"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Entfernen von Spalten\", \"drop\", [\"dtm\", \"ref_datetime\", \"valid_time\", \"valid_datetime\"])\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vorverarbeitung.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4 Generierung von neuen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitbasierte Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tageszeit\n",
    "df_merged[\"hour\"] = df_merged[\"dtm\"].dt.hour\n",
    "# Monat oder Saison\n",
    "df_merged[\"month\"] = df_merged[\"dtm\"].dt.month\n",
    "df_merged[\"season\"] = df_merged[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"lag_1\"] = df_merged[\"Solar_MWh\"].shift(1)\n",
    "df_merged[\"lag_24\"] = df_merged[\"Solar_MWh\"].shift(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Features (Gleitender Durchschnitt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"rolling_mean_24\"] = df_merged[\"Solar_MWh\"].rolling(window=24).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktion von Wetter und Zeit\n",
    "- temp_radiation_interaction: Produkt von Temperatur und Sonneneinstrahlung\n",
    "- cloud_hour_interaction: Produkt von CloudCover und Stunde des Tages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"temp_radiation_interaction\"] = (\n",
    "    df_merged[\"Temperature\"] * df_merged[\"SolarDownwardRadiation\"]\n",
    ")\n",
    "df_merged[\"cloud_hour_interaction\"] = (\n",
    "    df_merged[\"CloudCover\"] * df_merged[\"hour\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Merkmale\n",
    "Verhältnis von erzeugtem Strom zur verfügbaren Kapazität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"solar_efficiency\"] = df_merged[\"Solar_MWh\"] / df_merged[\"Solar_capacity_mwp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation von Wetterattributen:\n",
    "- scaled_temperature: Skaliere Temperatur auf den Bereich [0, 1].\n",
    "- adjusted_radiation: Negative Werte auf 0 setzen (falls noch nicht gemacht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_merged[\"scaled_temperature\"] = scaler.fit_transform(\n",
    "    df_merged[[\"Temperature\"]]\n",
    ")\n",
    "df_merged[\"adjusted_radiation\"] = df_merged[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 5 Modell trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung), (\"Linear-Model Training\", LinearRegression())])\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung von Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "ridge = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (Ridge):\", ridge.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Ridge):\", -ridge.best_score_)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = GridSearchCV(Lasso(max_iter=10000), param_grid, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"Best alpha (Lasso):\", lasso.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Lasso):\", -lasso.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 2: Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Best params (Decision Tree):\", tree.best_params_)\n",
    "print(\"Best RMSE (Decision Tree):\", -tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 3: Ensemble-Modell (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "forest = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Best params (Random Forest):\", forest.best_params_)\n",
    "print(\"Best RMSE (Random Forest):\", -forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wichtigste Features bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Linear\n",
    "linear_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": pipe_linear.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", linear_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Ridge\n",
    "ridge_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": ridge.best_estimator_.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", ridge_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Random Forest\n",
    "forest_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    #\"Importance\": forest.best_estimator_.feature_importances_\n",
    "})#.sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Random Forest Feature Importance:\\n\", forest_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfassung | Wenig Zellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful testing Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtm</th>\n",
       "      <th>ref_datetime</th>\n",
       "      <th>Solar_capacity_mwp</th>\n",
       "      <th>Solar_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dtm, ref_datetime, Solar_capacity_mwp, Solar_MWh]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammengefassetes Modelltraining ohne zusätzliche Zellen\n",
    "# ? Kommentare sind gehighlighted mit der \"Better Comments\" Extension\n",
    "# * Bibliotheken laden und Daten einlesen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von NaN-Werten \n",
    "# TODO Statt .dropna() eine Imputation einsetzen\n",
    "# ? Beim Forecast kann es ignoriert werden, da es im Transformer verwendet wird (aber erst im nach dem Merge)\n",
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.dropna()\n",
    "# df_forecasts = df_forecasts.dropna()\n",
    "# Spalte SolarDownwardRadiation\n",
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "# Spalte CloudCover\n",
    "df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "# Spalte Temperature\n",
    "df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von Negativen Werten\n",
    "# TODO Kann auch ignoriert werden\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Merge von Test-/Trainingsdaten mit Forecast-Dataset\n",
    "# TODO Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vom fehlerhaften Merge\n",
    "# // df_merged = df_merged.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test1 = df_merged_test1.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test2 = df_merged_test2.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering und Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeitbasiert Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_time in merged_list:  \n",
    "    # Tageszeit\n",
    "    add_time[\"hour\"] = add_time[\"dtm\"].dt.hour\n",
    "    add_time[\"day_of_week\"] = add_time[\"dtm\"].dt.day_of_week\n",
    "    # Monat oder Saison\n",
    "    add_time[\"month\"] = add_time[\"dtm\"].dt.month\n",
    "    add_time[\"season\"] = add_time[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wetterbasierte Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Interaktion zwischen Sonneneinstrahlung und Temperatur: Hohe Temperaturen können die Effizienz von Solaranlagen reduzieren, trotz hoher Sonneneinstrahlung\n",
    "    add_weather[\"Sun_CloudCover\"] = add_weather[\"Temperature\"] * add_weather[\"SolarDownwardRadiation\"]\n",
    "    # Bewölkerungsdynamik\n",
    "    add_weather[\"CloudCover_change\"] = add_weather[\"CloudCover\"].diff()\n",
    "    \n",
    "df_merged = df_merged.dropna()\n",
    "df_merged_test1 = df_merged_test1.dropna()\n",
    "df_merged_test2 = df_merged_test2.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historische Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Rolling Average für Sonneneinstrahlung (z. B. über die letzten 3 Stunden)\n",
    "    add_weather['AvgSolarRadiation_last_3h'] = add_weather['SolarDownwardRadiation'].rolling(window=3).mean()\n",
    "    # Lag-Feature: Sonneneinstrahlung der letzten Stunde\n",
    "    add_weather['SolarRadiation_lag_1h'] = add_weather['SolarDownwardRadiation'].shift(1)\n",
    "    # Lag-Feature: Temperatur der letzten Stunde\n",
    "    add_weather['Temperature_lag_1h'] = add_weather['Temperature'].shift(1)\n",
    "    \n",
    "df_merged = df_merged.dropna()\n",
    "df_merged_test1 = df_merged_test1.dropna()\n",
    "df_merged_test2 = df_merged_test2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# * Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)\n",
    "# ! Vorverarbeitung: Transformer\n",
    "vorverarbeitung = ColumnTransformer([\n",
    "    # (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"Weather Model\"]),\n",
    "    #(\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Skalieren\", StandardScaler(), [\"SolarDownwardRadiation\", #\"Solar_capacity_mwp\", \"CloudCover\", \"Temperature\", \n",
    "                                    #\"season\", #\"hour\", \"month\", # Zeitbasierte Features  \n",
    "                                    # \"Sun_CloudCover\", 'AvgSolarRadiation_last_3h', 'SolarRadiation_lag_1h', 'Temperature_lag_1h', # Wetterbasierte Features\n",
    "                                     ]),\n",
    "    (\"drop_columns\", \"drop\", [\"dtm\", \"valid_time\", \"valid_datetime\", \"CloudCover\", \"Solar_capacity_mwp\", \"CloudCover\", \"Temperature\", \"ref_datetime\"]) # \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN-Werte:\", X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lineares Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'fit_intercept': True}\n",
      "RMSE: 68.86520046946798\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lineares Modell\n",
    "# * Hyperparametersuche\n",
    "param_grid = {\"fit_intercept\": [True, False]}\n",
    "\n",
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                        (\"gs_linear\", GridSearchCV(LinearRegression(), param_grid))\n",
    "                         ])\n",
    "\n",
    "# Trainiere Lineares Modell\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_linear.named_steps[\"gs_linear\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "# RMSE\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Vorhersage für Testdaten 1 und 2\n",
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_linear.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(66.22538365900702)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>6.355272e+12</td>\n",
       "      <td>6.355272e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>6.355272e+12</td>\n",
       "      <td>6.355272e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>1.722975e+02</td>\n",
       "      <td>1.723000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skalieren__season</td>\n",
       "      <td>-7.469924e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature   Coefficient  Feature_Importance\n",
       "0  O-H-Encoding__Weather Model_DWD ICON  6.355272e+12        6.355272e+12\n",
       "1  O-H-Encoding__Weather Model_NCEP GFS  6.355272e+12        6.355272e+12\n",
       "2     Skalieren__SolarDownwardRadiation  1.722975e+02        1.723000e+02\n",
       "3                     Skalieren__season -7.469924e-01        7.000000e-01"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_linear_model = pipe_linear.named_steps[\"gs_linear\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_linear.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_linear_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs().round(1)\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.05, 0.1, 0.5, 1, 10, 20, 40, 80, 100, 125, 200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 1}\n",
      "RMSE: 66.10880766938034\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Ridge Modell\n",
    "pipe_ridge = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_ridge\", GridSearchCV(Ridge(), param_grid))\n",
    "                       ])\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_ridge.named_steps[\"gs_ridge\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "\n",
    "y_pred = pipe_ridge.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_ridge.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_ridge.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>172.231665</td>\n",
       "      <td>172.231665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-13.301886</td>\n",
       "      <td>13.301886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>13.301886</td>\n",
       "      <td>13.301886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Coefficient  Feature_Importance\n",
       "2     Skalieren__SolarDownwardRadiation   172.231665          172.231665\n",
       "1  O-H-Encoding__Weather Model_NCEP GFS   -13.301886           13.301886\n",
       "0  O-H-Encoding__Weather Model_DWD ICON    13.301886           13.301886"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_ridge_model = pipe_ridge.named_steps[\"gs_ridge\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_ridge.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_ridge_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 0.01}\n",
      "RMSE: 66.22314605768675\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lasso Modell\n",
    "pipe_lasso = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_lasso\", GridSearchCV(Lasso(), param_grid))\n",
    "                       ])\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_lasso.named_steps[\"gs_lasso\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_lasso.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_lasso.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_lasso.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>172.225590</td>\n",
       "      <td>172.225590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>26.564496</td>\n",
       "      <td>26.564496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Coefficient  Feature_Importance\n",
       "2     Skalieren__SolarDownwardRadiation   172.225590          172.225590\n",
       "0  O-H-Encoding__Weather Model_DWD ICON    26.564496           26.564496\n",
       "1  O-H-Encoding__Weather Model_NCEP GFS    -0.000000            0.000000"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_lasso_model = pipe_lasso.named_steps[\"gs_lasso\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_lasso.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_lasso_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 5, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "RMSE: 60.98071413224245\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: DecisionTree Modell\n",
    "pipe_tree = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_tree\", GridSearchCV(DecisionTreeRegressor(), param_grid))\n",
    "                       ])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_tree.named_steps[\"gs_tree\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_tree.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_tree.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_tree.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>0.981349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>0.013140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skalieren__CloudCover</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skalieren__Temperature</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Importance\n",
       "4     Skalieren__SolarDownwardRadiation    0.981349\n",
       "1  O-H-Encoding__Weather Model_NCEP GFS    0.013140\n",
       "0  O-H-Encoding__Weather Model_DWD ICON    0.003823\n",
       "2                 Skalieren__CloudCover    0.001687\n",
       "3                Skalieren__Temperature    0.000000"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_tree_model = pipe_tree.named_steps[\"gs_tree\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_tree.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_tree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "# !Pipeline: Random Forest Modell\n",
    "pipe_rand_frst = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_rand_frst\", GridSearchCV(RandomForestRegressor(random_state=42), param_grid))\n",
    "                       ])\n",
    "pipe_rand_frst.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_randtree_model = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_rand_frst.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_randtree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
