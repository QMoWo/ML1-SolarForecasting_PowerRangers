{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotheken/Einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beobachtung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Zeilen anpassen (durchschnitt, vorheriger Wert) oder löschen\n",
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train.Solar_MWh.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[df_forecasts.SolarDownwardRadiation.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit NaN-Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Umgang mit NaN-Werten in df_train__\n",
    "- Betroffene Zeilen 4 von 19968 (ca.0,02%)\n",
    "- Mein Ansatz: Zeilen, wo bei `Solar_MWh` NaN auftaucht, löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Umgang mit NaN-Werten in df_forecasts**\n",
    "- Betroffene Zeilen: max. 1226 von 606797 (ca. 0,2%)\n",
    "- Mein Ansatz: Daten behalten und Auffüllen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spalte SolarDownwardRadiation\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "\n",
    "# # Spalte CloudCover\n",
    "# df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "\n",
    "# # Spalte Temperature\n",
    "# df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts = df_forecasts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validierung nach der Bereinigung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN-Werte in df_train:\", df_train.isna().sum())\n",
    "print(\"NaN-Werte in df_forecasts:\", df_forecasts.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test1.isna().sum())\n",
    "print(\"NaN-Werte in df_train:\", df_test2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umgang mit Negativen Werten `SolarDownwardRadiation` (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative SolarDownwardRadiation anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 Untersuchung der Energiedaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wie viele Datenpunkte, die vorhergesagt werden sollen, gibt es in den Trainings- bzw. Testdaten?\n",
    "train_points = len(df_train)\n",
    "\n",
    "# Anzahl der Datenpunkte in den beiden Testsets\n",
    "test1_points = len(df_test1)\n",
    "test2_points = len(df_test2)\n",
    "\n",
    "print(f\"Trainingsdatenpunkte: {train_points}\")\n",
    "print(f\"Testdatenpunkte - Test1: {test1_points}, Test2: {test2_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tagesverlauf visualisieren\n",
    "# (Zufälige)Geburtstage auswählen, bzw. Frühlings-, Sommer- und Winterzeit\n",
    "birthdates = [\"2022-05-21\", \"2022-07-28\", \"2022-12-16\"]\n",
    "birthdates = pd.to_datetime(birthdates) # Strings in datetime umwandeln\n",
    "\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"dtm\"]).dt.date  # Extrahiere das Datum\n",
    "\n",
    "# Filter für die ausgewählten Tage\n",
    "filtered_data = df_train[df_train[\"date\"].isin(birthdates.date)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for date in birthdates:\n",
    "    daily_data = filtered_data[filtered_data[\"date\"] == date.date()]\n",
    "    plt.plot(\n",
    "        pd.to_datetime(daily_data[\"dtm\"]).dt.hour,\n",
    "        daily_data[\"Solar_MWh\"],\n",
    "        label=str(date.date())\n",
    "    )\n",
    "plt.xlabel(\"Stunde des Tages\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Tagesverlauf der Stromerzeugung\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-05-21  Frühling <br>\n",
    "2022-07-28 -> Sommer <br>\n",
    "2022-12-16 -> Winter <br>\n",
    "Man erkennt deutlich, dass logischerweise Nachts kein Strom produziert wird und der Tag der wichtige Teil für die Stromerzeugung. Auch erkennbar ist, dass der Winter weniger Strom produziert, was sehr stark an der Wolkenbedeckung liegen kann und die Tageszeit kürzer anhält als Frühling und Sommer.\n",
    "Einen kleinen Ausreißer erkennt man beim Frühling, was bei ca. 10-12Uhr kurz wenig Strom produziert. Das könnte an einem Regenschauer liegen oder anderen technischen Fehlern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gesamtverlauf visualisieren\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pd.to_datetime(df_train[\"dtm\"]), df_train[\"Solar_MWh\"], color=\"blue\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Stromerzeugung (Solar_MWh)\")\n",
    "plt.title(\"Gesamtverlauf der Stromerzeugung (Trainingsdaten)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Sommer steigt die Stromerzeugung, da es länger hell bleibt und wenig Wolkenbedeckung hat. <br>\n",
    "Im Winter sinkt die Stromerzeugung, da es schneller dunkel wird und weniger Sonnenschein tagsüber hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2 Merge und Untersuchung von Zusammenhänge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge mit Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test1 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test2 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineered Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot erstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Plot erstellen\n",
    "# Scatterplots für jede Wettervariable vs. Solar_MWh\n",
    "weather_attributes = [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, attr in enumerate(weather_attributes):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.scatterplot(data=df_merged, x=attr, y=\"Solar_MWh\", alpha=0.5)\n",
    "    plt.title(f\"{attr} vs Solar_MWh\")\n",
    "    plt.xlabel(attr)\n",
    "    plt.ylabel(\"Solar_MWh\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Erkennung von Zusammenhängen\n",
    "# Korrelationen zwischen Wetterattributen und Solar_MWh berechnen\n",
    "correlations = df_merged[weather_attributes + [\"Solar_MWh\"]].corr()[\"Solar_MWh\"].sort_values(ascending=False)\n",
    "print(\"Korrelationen mit Solar_MWh:\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wolkenbedeckung weißt auf einen schwachen Zusammenhang zur Stromerzeugung, während die Sonneneinstrahlung wichtiger ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3 Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behandlung von Ausreißern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung von Solar_MWh\n",
    "sns.histplot(df_train[\"Solar_MWh\"], kde=True, bins=30)\n",
    "plt.title(\"Train - Verteilung von Solar_MWh\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot zur Erkennung von Ausreißern\n",
    "sns.boxplot(x=df_train[\"Solar_MWh\"])\n",
    "plt.title(\"Train - Boxplot von Solar_MWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Es wäre für mich eine logische Entscheidung die Ausreißer 0 mitzunehmen ins Modell, weil diese möglicherweise echte Werte sind. Das liegt daran, das Nachts keine Stromproduktion stattfindet, sowie im Winter die Nacht länger andauert. <br>\n",
    "Zusätzlich ist es tagsüber deutlich inkonsistenter, da verschiedene Feature (Sonnenstrahlung, Wolkenbedeckung, Temperatur) Einfluss auf die die Stromproduktion nehmen.\n",
    "\n",
    "Zusammengefasst entscheide ich mich die Ausreißer nicht rauszunehmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorverarbeitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung = ColumnTransformer([\n",
    "    (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"Weather Model\"]),\n",
    "    (\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\" ]),\n",
    "    (\"Skalieren\", StandardScaler(), [\"Solar_capacity_mwp\", \"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Entfernen von Spalten\", \"drop\", [\"dtm\", \"ref_datetime\", \"valid_time\", \"valid_datetime\"])\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vorverarbeitung.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4 Generierung von neuen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitbasierte Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tageszeit\n",
    "df_merged[\"hour\"] = df_merged[\"dtm\"].dt.hour\n",
    "# Monat oder Saison\n",
    "df_merged[\"month\"] = df_merged[\"dtm\"].dt.month\n",
    "df_merged[\"season\"] = df_merged[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"lag_1\"] = df_merged[\"Solar_MWh\"].shift(1)\n",
    "df_merged[\"lag_24\"] = df_merged[\"Solar_MWh\"].shift(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Features (Gleitender Durchschnitt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"rolling_mean_24\"] = df_merged[\"Solar_MWh\"].rolling(window=24).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktion von Wetter und Zeit\n",
    "- temp_radiation_interaction: Produkt von Temperatur und Sonneneinstrahlung\n",
    "- cloud_hour_interaction: Produkt von CloudCover und Stunde des Tages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"temp_radiation_interaction\"] = (\n",
    "    df_merged[\"Temperature\"] * df_merged[\"SolarDownwardRadiation\"]\n",
    ")\n",
    "df_merged[\"cloud_hour_interaction\"] = (\n",
    "    df_merged[\"CloudCover\"] * df_merged[\"hour\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Merkmale\n",
    "Verhältnis von erzeugtem Strom zur verfügbaren Kapazität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"solar_efficiency\"] = df_merged[\"Solar_MWh\"] / df_merged[\"Solar_capacity_mwp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation von Wetterattributen:\n",
    "- scaled_temperature: Skaliere Temperatur auf den Bereich [0, 1].\n",
    "- adjusted_radiation: Negative Werte auf 0 setzen (falls noch nicht gemacht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_merged[\"scaled_temperature\"] = scaler.fit_transform(\n",
    "    df_merged[[\"Temperature\"]]\n",
    ")\n",
    "df_merged[\"adjusted_radiation\"] = df_merged[\"SolarDownwardRadiation\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 5 Modell trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung), (\"Linear-Model Training\", LinearRegression())])\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung von Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "ridge = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (Ridge):\", ridge.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Ridge):\", -ridge.best_score_)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = GridSearchCV(Lasso(max_iter=10000), param_grid, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"Best alpha (Lasso):\", lasso.best_params_[\"alpha\"])\n",
    "print(\"Best RMSE (Lasso):\", -lasso.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 2: Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Best params (Decision Tree):\", tree.best_params_)\n",
    "print(\"Best RMSE (Decision Tree):\", -tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 3: Ensemble-Modell (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "forest = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Best params (Random Forest):\", forest.best_params_)\n",
    "print(\"Best RMSE (Random Forest):\", -forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wichtigste Features bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Linear\n",
    "linear_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": pipe_linear.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", linear_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Ridge\n",
    "ridge_coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": ridge.best_estimator_.coef_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Ridge Feature Importance:\\n\", ridge_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Wichtigkeiten für Random Forest\n",
    "forest_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    #\"Importance\": forest.best_estimator_.feature_importances_\n",
    "})#.sort_values(by=\"Importance\", ascending=False)\n",
    "print(\"Random Forest Feature Importance:\\n\", forest_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfassung | Wenig Zellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5 | 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful testing Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtm</th>\n",
       "      <th>ref_datetime</th>\n",
       "      <th>Solar_capacity_mwp</th>\n",
       "      <th>Solar_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dtm, ref_datetime, Solar_capacity_mwp, Solar_MWh]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.Solar_MWh.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammengefassetes Modelltraining ohne zusätzliche Zellen\n",
    "# ? Kommentare sind gehighlighted mit der \"Better Comments\" Extension\n",
    "# * Bibliotheken laden und Daten einlesen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_test1 = pd.read_parquet(\"../Daten/energy_test1.parquet\")\n",
    "df_test2 = pd.read_parquet(\"../Daten/energy_test2.parquet\")\n",
    "df_train = pd.read_parquet(\"../Daten/energy_train.parquet\")\n",
    "df_forecasts = pd.read_parquet(\"../Daten/forecasts.parquet\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von NaN-Werten \n",
    "# TODO Statt .dropna() eine Imputation einsetzen\n",
    "# ? Beim Forecast kann es ignoriert werden, da es im Transformer verwendet wird (aber erst im nach dem Merge)\n",
    "df_train = df_train.dropna()\n",
    "df_test1 = df_test1.dropna()\n",
    "df_test2 = df_test2.dropna()\n",
    "# df_forecasts = df_forecasts.dropna()\n",
    "# Spalte SolarDownwardRadiation\n",
    "df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].interpolate(method=\"linear\")\n",
    "# Spalte CloudCover\n",
    "df_forecasts[\"CloudCover\"] = df_forecasts[\"CloudCover\"].fillna(df_forecasts[\"CloudCover\"].median())\n",
    "# Spalte Temperature\n",
    "df_forecasts[\"Temperature\"] = df_forecasts[\"Temperature\"].interpolate(method=\"linear\")\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Umgang von Negativen Werten\n",
    "# TODO Kann auch ignoriert werden\n",
    "# df_forecasts[\"SolarDownwardRadiation\"] = df_forecasts[\"SolarDownwardRadiation\"].clip(lower=0)\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# ! Merge von Test-/Trainingsdaten mit Forecast-Dataset\n",
    "# TODO Konvertiere `ref_datetime` und `dtm` zu datetime-Objekten\n",
    "df_train[\"ref_datetime\"] = pd.to_datetime(df_train[\"ref_datetime\"])\n",
    "df_test1[\"ref_datetime\"] = pd.to_datetime(df_test1[\"ref_datetime\"])\n",
    "df_test2[\"ref_datetime\"] = pd.to_datetime(df_test2[\"ref_datetime\"])\n",
    "df_train[\"dtm\"] = pd.to_datetime(df_train[\"dtm\"])\n",
    "df_test1[\"dtm\"] = pd.to_datetime(df_test1[\"dtm\"])\n",
    "df_test2[\"dtm\"] = pd.to_datetime(df_test2[\"dtm\"])\n",
    "\n",
    "# Gültigen Zeitpunkt für Wettervorhersagen berechnen\n",
    "df_forecasts[\"valid_datetime\"] = df_forecasts[\"ref_datetime\"] + pd.to_timedelta(df_forecasts[\"valid_time\"], unit=\"h\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_train,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test1 = pd.merge(\n",
    "    df_test1,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_merged_test2 = pd.merge(\n",
    "    df_test2,\n",
    "    df_forecasts,\n",
    "    left_on=[\"dtm\", \"ref_datetime\"],\n",
    "    right_on=[\"valid_datetime\", \"ref_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vom fehlerhaften Merge\n",
    "# // df_merged = df_merged.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test1 = df_merged_test1.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})\n",
    "# // df_merged_test2 = df_merged_test2.rename(columns={\"ref_datetime_x\": \"date_train\", \"ref_datetime_y\": \"date_weather\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering und Vorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeitbasiert Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für zyklische Transformation | Abruf im ColumnTransformer\n",
    "def cyclical_features(X):\n",
    "    X = X.copy()\n",
    "    X[\"hour_sin\"] = np.sin(2 * np.pi * X[\"hour\"] / 24)\n",
    "    X[\"hour_cos\"] = np.cos(2 * np.pi * X[\"hour\"] / 24)\n",
    "    return X[[\"hour_sin\", \"hour_cos\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode zur Bestimmung des Zeitraums\n",
    "def assign_time_period(hour):\n",
    "    if 5 <= hour < 9:\n",
    "        return 'Morgen'\n",
    "    elif 9 <= hour < 12:\n",
    "        return 'Vormittag'\n",
    "    elif 12 <= hour < 15:\n",
    "        return 'Mittag'\n",
    "    elif 15 <= hour < 18:\n",
    "        return 'Nachmittag'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Abend'\n",
    "    else:\n",
    "        return 'Nacht'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_time in merged_list:  \n",
    "    # Tageszeit\n",
    "    add_time[\"hour\"] = add_time[\"dtm\"].dt.hour\n",
    "    add_time[\"time_period\"] = add_time[\"hour\"].apply(assign_time_period)\n",
    "    # add_time[\"day_of_week\"] = add_time[\"dtm\"].dt.day_of_week\n",
    "    # Monat oder Saison\n",
    "    # add_time[\"month\"] = add_time[\"dtm\"].dt.month\n",
    "    # add_time[\"season\"] = add_time[\"month\"].apply(lambda x: (x % 12 + 3) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wetterbasierte Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Interaktion zwischen Sonneneinstrahlung und Temperatur: Hohe Temperaturen können die Effizienz von Solaranlagen reduzieren, trotz hoher Sonneneinstrahlung\n",
    "    # add_weather[\"Sun_CloudCover\"] = add_weather[\"Temperature\"] * add_weather[\"SolarDownwardRadiation\"]\n",
    "    # Bewölkerungsdynamik\n",
    "    add_weather[\"CloudCover_change\"] = add_weather[\"CloudCover\"].diff()\n",
    "    \n",
    "df_merged = df_merged.dropna()\n",
    "df_merged_test1 = df_merged_test1.dropna()\n",
    "df_merged_test2 = df_merged_test2.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historische Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Feature Engineering\n",
    "merged_list = [df_merged, df_merged_test1, df_merged_test2]\n",
    "\n",
    "for add_weather in merged_list:  \n",
    "    # Rolling Average für Sonneneinstrahlung (z. B. über die letzten 3 Stunden)\n",
    "    add_weather['AvgSolarRadiation_last_3h'] = add_weather['SolarDownwardRadiation'].rolling(window=3).mean()\n",
    "    # # Lag-Feature: Sonneneinstrahlung der letzten Stunde\n",
    "    # add_weather['SolarRadiation_lag_1h'] = add_weather['SolarDownwardRadiation'].shift(1)\n",
    "    # # Lag-Feature: Temperatur der letzten Stunde\n",
    "    # add_weather['Temperature_lag_1h'] = add_weather['Temperature'].shift(1)\n",
    "    \n",
    "df_merged = df_merged.dropna()\n",
    "df_merged_test1 = df_merged_test1.dropna()\n",
    "df_merged_test2 = df_merged_test2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "y = df_merged.pop(\"Solar_MWh\")\n",
    "# * Split in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, y, test_size=0.2, random_state=42)\n",
    "# ! Vorverarbeitung: Transformer\n",
    "vorverarbeitung = ColumnTransformer([\n",
    "    (\"O-H-Encoding\", OneHotEncoder(handle_unknown=\"ignore\"),[\"time_period\"]),\n",
    "    (\"Zyklisch_hour\", FunctionTransformer(cyclical_features), [\"hour\"]),\n",
    "    #(\"nanTransform\", SimpleImputer(missing_values=np.nan, strategy=\"mean\"), [\"SolarDownwardRadiation\", \"CloudCover\", \"Temperature\"]),\n",
    "    (\"Skalieren\", StandardScaler(), [\"SolarDownwardRadiation\"#, \"Solar_capacity_mwp\", \"CloudCover\", \"Temperature\",\n",
    "                                     #\"AvgSolarRadiation_last_3h\" # extra Feature \n",
    "                                     ]),\n",
    "    (\"drop_columns\", \"drop\", [\"dtm\", \"valid_time\", \"valid_datetime\", \"CloudCover\", \"Solar_capacity_mwp\", \"CloudCover\", \"Temperature\", \"ref_datetime\", \"hour\"])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN-Werte:\", X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lineares Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'fit_intercept': False}\n",
      "RMSE: 65.21801950203977\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lineares Modell\n",
    "# * Hyperparametersuche\n",
    "param_grid = {\"fit_intercept\": [True, False]}\n",
    "\n",
    "pipe_linear = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                        (\"gs_linear\", GridSearchCV(LinearRegression(), param_grid, cv=5))\n",
    "                         ])\n",
    "\n",
    "# Trainiere Lineares Modell\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_linear.named_steps[\"gs_linear\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "# RMSE\n",
    "y_pred = pipe_linear.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Vorhersage für Testdaten 1 und 2\n",
    "y_pred = pipe_linear.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_linear.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(65.21801950203977)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer Zyklisch_hour (type FunctionTransformer) does not provide get_feature_names_out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m best_linear_model \u001b[38;5;241m=\u001b[39m pipe_linear\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs_linear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Abrufe der Feature-Namen nach Vorverarbeitung\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m pipe_linear\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVorverarbeitung\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Erstelle einen DataFrame mit den Koeffizienten\u001b[39;00m\n\u001b[0;32m      8\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature_names,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_linear_model\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     11\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\achim\\anaconda3\\envs\\dsc4\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:630\u001b[0m, in \u001b[0;36mColumnTransformer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    623\u001b[0m transformer_with_feature_names_out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, trans, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    625\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     skip_empty_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    628\u001b[0m     skip_drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    629\u001b[0m ):\n\u001b[1;32m--> 630\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_feature_name_out_for_transformer(\n\u001b[0;32m    631\u001b[0m         name, trans, input_features\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\achim\\anaconda3\\envs\\dsc4\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:593\u001b[0m, in \u001b[0;36mColumnTransformer._get_feature_name_out_for_transformer\u001b[1;34m(self, name, trans, feature_names_in)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# An actual transformer\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trans, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    594\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(trans)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot provide get_feature_names_out.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m     )\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mget_feature_names_out(names)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Transformer Zyklisch_hour (type FunctionTransformer) does not provide get_feature_names_out."
     ]
    }
   ],
   "source": [
    "\n",
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_linear_model = pipe_linear.named_steps[\"gs_linear\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_linear.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_linear_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs().round(1)\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge und Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für Ridge und Lasso\n",
    "param_grid = {'alpha': [0.01, 0.05, 0.1, 0.5, 1, 10, 20, 40, 80, 100, 125, 200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 1}\n",
      "RMSE: 60.48362515400969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\4049795879.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\4049795879.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test2[\"Solar_MWh_pred\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Ridge Modell\n",
    "pipe_ridge = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_ridge\", GridSearchCV(Ridge(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_ridge.named_steps[\"gs_ridge\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_ridge.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_ridge.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_ridge.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skalieren__AvgSolarRadiation_last_3h</td>\n",
       "      <td>137.291624</td>\n",
       "      <td>137.291624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O-H-Encoding__hour_10</td>\n",
       "      <td>74.636795</td>\n",
       "      <td>74.636795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__hour_9</td>\n",
       "      <td>66.845041</td>\n",
       "      <td>66.845041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O-H-Encoding__hour_11</td>\n",
       "      <td>64.137040</td>\n",
       "      <td>64.137040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>O-H-Encoding__hour_17</td>\n",
       "      <td>-50.128374</td>\n",
       "      <td>50.128374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>O-H-Encoding__hour_12</td>\n",
       "      <td>45.929280</td>\n",
       "      <td>45.929280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>O-H-Encoding__hour_16</td>\n",
       "      <td>-45.693106</td>\n",
       "      <td>45.693106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>O-H-Encoding__hour_18</td>\n",
       "      <td>-37.199729</td>\n",
       "      <td>37.199729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__hour_8</td>\n",
       "      <td>36.629269</td>\n",
       "      <td>36.629269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O-H-Encoding__hour_13</td>\n",
       "      <td>30.495329</td>\n",
       "      <td>30.495329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O-H-Encoding__hour_15</td>\n",
       "      <td>-27.544635</td>\n",
       "      <td>27.544635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>O-H-Encoding__hour_19</td>\n",
       "      <td>-22.642399</td>\n",
       "      <td>22.642399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>18.329118</td>\n",
       "      <td>18.329118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__hour_6</td>\n",
       "      <td>-15.435495</td>\n",
       "      <td>15.435495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__hour_5</td>\n",
       "      <td>-14.726392</td>\n",
       "      <td>14.726392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>O-H-Encoding__hour_20</td>\n",
       "      <td>-14.466222</td>\n",
       "      <td>14.466222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>O-H-Encoding__hour_21</td>\n",
       "      <td>-12.576593</td>\n",
       "      <td>12.576593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__hour_4</td>\n",
       "      <td>-12.380909</td>\n",
       "      <td>12.380909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>O-H-Encoding__hour_23</td>\n",
       "      <td>-12.324458</td>\n",
       "      <td>12.324458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>O-H-Encoding__hour_22</td>\n",
       "      <td>-12.269598</td>\n",
       "      <td>12.269598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__hour_3</td>\n",
       "      <td>-12.054374</td>\n",
       "      <td>12.054374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__hour_0</td>\n",
       "      <td>-12.008888</td>\n",
       "      <td>12.008888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__hour_2</td>\n",
       "      <td>-11.930136</td>\n",
       "      <td>11.930136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__hour_1</td>\n",
       "      <td>-11.926063</td>\n",
       "      <td>11.926063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-5.146803</td>\n",
       "      <td>5.146803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>5.146803</td>\n",
       "      <td>5.146803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__hour_7</td>\n",
       "      <td>3.516720</td>\n",
       "      <td>3.516720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O-H-Encoding__hour_14</td>\n",
       "      <td>3.117896</td>\n",
       "      <td>3.117896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Coefficient  Feature_Importance\n",
       "27  Skalieren__AvgSolarRadiation_last_3h   137.291624          137.291624\n",
       "12                 O-H-Encoding__hour_10    74.636795           74.636795\n",
       "11                  O-H-Encoding__hour_9    66.845041           66.845041\n",
       "13                 O-H-Encoding__hour_11    64.137040           64.137040\n",
       "19                 O-H-Encoding__hour_17   -50.128374           50.128374\n",
       "14                 O-H-Encoding__hour_12    45.929280           45.929280\n",
       "18                 O-H-Encoding__hour_16   -45.693106           45.693106\n",
       "20                 O-H-Encoding__hour_18   -37.199729           37.199729\n",
       "10                  O-H-Encoding__hour_8    36.629269           36.629269\n",
       "15                 O-H-Encoding__hour_13    30.495329           30.495329\n",
       "17                 O-H-Encoding__hour_15   -27.544635           27.544635\n",
       "21                 O-H-Encoding__hour_19   -22.642399           22.642399\n",
       "26     Skalieren__SolarDownwardRadiation    18.329118           18.329118\n",
       "8                   O-H-Encoding__hour_6   -15.435495           15.435495\n",
       "7                   O-H-Encoding__hour_5   -14.726392           14.726392\n",
       "22                 O-H-Encoding__hour_20   -14.466222           14.466222\n",
       "23                 O-H-Encoding__hour_21   -12.576593           12.576593\n",
       "6                   O-H-Encoding__hour_4   -12.380909           12.380909\n",
       "25                 O-H-Encoding__hour_23   -12.324458           12.324458\n",
       "24                 O-H-Encoding__hour_22   -12.269598           12.269598\n",
       "5                   O-H-Encoding__hour_3   -12.054374           12.054374\n",
       "2                   O-H-Encoding__hour_0   -12.008888           12.008888\n",
       "4                   O-H-Encoding__hour_2   -11.930136           11.930136\n",
       "3                   O-H-Encoding__hour_1   -11.926063           11.926063\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS    -5.146803            5.146803\n",
       "0   O-H-Encoding__Weather Model_DWD ICON     5.146803            5.146803\n",
       "9                   O-H-Encoding__hour_7     3.516720            3.516720\n",
       "16                 O-H-Encoding__hour_14     3.117896            3.117896"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_ridge_model = pipe_ridge.named_steps[\"gs_ridge\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_ridge.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_ridge_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'alpha': 0.01}\n",
      "RMSE: 63.133776437619986\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: Lasso Modell\n",
    "pipe_lasso = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_lasso\", GridSearchCV(Lasso(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_lasso.named_steps[\"gs_lasso\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_lasso.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_lasso.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_lasso.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>147.228233</td>\n",
       "      <td>147.228233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O-H-Encoding__hour_11</td>\n",
       "      <td>90.640776</td>\n",
       "      <td>90.640776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O-H-Encoding__hour_10</td>\n",
       "      <td>86.642888</td>\n",
       "      <td>86.642888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>O-H-Encoding__hour_12</td>\n",
       "      <td>85.894078</td>\n",
       "      <td>85.894078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>O-H-Encoding__hour_13</td>\n",
       "      <td>77.574636</td>\n",
       "      <td>77.574636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O-H-Encoding__hour_9</td>\n",
       "      <td>68.273353</td>\n",
       "      <td>68.273353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>O-H-Encoding__hour_14</td>\n",
       "      <td>56.062705</td>\n",
       "      <td>56.062705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>O-H-Encoding__hour_8</td>\n",
       "      <td>32.012957</td>\n",
       "      <td>32.012957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>O-H-Encoding__hour_15</td>\n",
       "      <td>26.115334</td>\n",
       "      <td>26.115334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>23.120959</td>\n",
       "      <td>23.120959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O-H-Encoding__hour_6</td>\n",
       "      <td>-15.387498</td>\n",
       "      <td>15.387498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>O-H-Encoding__hour_17</td>\n",
       "      <td>-12.094568</td>\n",
       "      <td>12.094568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>O-H-Encoding__month_2</td>\n",
       "      <td>10.064275</td>\n",
       "      <td>10.064275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O-H-Encoding__hour_5</td>\n",
       "      <td>-10.053602</td>\n",
       "      <td>10.053602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>O-H-Encoding__hour_18</td>\n",
       "      <td>-7.843819</td>\n",
       "      <td>7.843819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-H-Encoding__season_1</td>\n",
       "      <td>-6.864659</td>\n",
       "      <td>6.864659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>O-H-Encoding__month_11</td>\n",
       "      <td>-6.015832</td>\n",
       "      <td>6.015832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>O-H-Encoding__month_4</td>\n",
       "      <td>5.952874</td>\n",
       "      <td>5.952874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>O-H-Encoding__month_12</td>\n",
       "      <td>-4.813466</td>\n",
       "      <td>4.813466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>O-H-Encoding__month_5</td>\n",
       "      <td>-4.635052</td>\n",
       "      <td>4.635052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O-H-Encoding__season_2</td>\n",
       "      <td>4.625092</td>\n",
       "      <td>4.625092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>O-H-Encoding__month_10</td>\n",
       "      <td>3.466945</td>\n",
       "      <td>3.466945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>O-H-Encoding__month_8</td>\n",
       "      <td>-3.354761</td>\n",
       "      <td>3.354761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>O-H-Encoding__month_9</td>\n",
       "      <td>3.086679</td>\n",
       "      <td>3.086679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>O-H-Encoding__month_7</td>\n",
       "      <td>2.336287</td>\n",
       "      <td>2.336287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O-H-Encoding__hour_4</td>\n",
       "      <td>-2.196889</td>\n",
       "      <td>2.196889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>O-H-Encoding__month_3</td>\n",
       "      <td>2.087444</td>\n",
       "      <td>2.087444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>O-H-Encoding__hour_19</td>\n",
       "      <td>-1.985795</td>\n",
       "      <td>1.985795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>O-H-Encoding__hour_16</td>\n",
       "      <td>1.746832</td>\n",
       "      <td>1.746832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-H-Encoding__season_3</td>\n",
       "      <td>-1.674755</td>\n",
       "      <td>1.674755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>O-H-Encoding__month_1</td>\n",
       "      <td>-0.814373</td>\n",
       "      <td>0.814373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O-H-Encoding__hour_0</td>\n",
       "      <td>-0.303561</td>\n",
       "      <td>0.303561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>O-H-Encoding__hour_22</td>\n",
       "      <td>-0.301442</td>\n",
       "      <td>0.301442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>O-H-Encoding__hour_21</td>\n",
       "      <td>-0.257575</td>\n",
       "      <td>0.257575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>O-H-Encoding__hour_20</td>\n",
       "      <td>-0.252140</td>\n",
       "      <td>0.252140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O-H-Encoding__season_4</td>\n",
       "      <td>0.037050</td>\n",
       "      <td>0.037050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O-H-Encoding__hour_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O-H-Encoding__hour_1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O-H-Encoding__hour_3</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O-H-Encoding__hour_7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>O-H-Encoding__hour_23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>O-H-Encoding__month_6</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Coefficient  Feature_Importance\n",
       "42     Skalieren__SolarDownwardRadiation   147.228233          147.228233\n",
       "17                 O-H-Encoding__hour_11    90.640776           90.640776\n",
       "16                 O-H-Encoding__hour_10    86.642888           86.642888\n",
       "18                 O-H-Encoding__hour_12    85.894078           85.894078\n",
       "19                 O-H-Encoding__hour_13    77.574636           77.574636\n",
       "15                  O-H-Encoding__hour_9    68.273353           68.273353\n",
       "20                 O-H-Encoding__hour_14    56.062705           56.062705\n",
       "14                  O-H-Encoding__hour_8    32.012957           32.012957\n",
       "21                 O-H-Encoding__hour_15    26.115334           26.115334\n",
       "0   O-H-Encoding__Weather Model_DWD ICON    23.120959           23.120959\n",
       "12                  O-H-Encoding__hour_6   -15.387498           15.387498\n",
       "23                 O-H-Encoding__hour_17   -12.094568           12.094568\n",
       "31                 O-H-Encoding__month_2    10.064275           10.064275\n",
       "11                  O-H-Encoding__hour_5   -10.053602           10.053602\n",
       "24                 O-H-Encoding__hour_18    -7.843819            7.843819\n",
       "2                 O-H-Encoding__season_1    -6.864659            6.864659\n",
       "40                O-H-Encoding__month_11    -6.015832            6.015832\n",
       "33                 O-H-Encoding__month_4     5.952874            5.952874\n",
       "41                O-H-Encoding__month_12    -4.813466            4.813466\n",
       "34                 O-H-Encoding__month_5    -4.635052            4.635052\n",
       "3                 O-H-Encoding__season_2     4.625092            4.625092\n",
       "39                O-H-Encoding__month_10     3.466945            3.466945\n",
       "37                 O-H-Encoding__month_8    -3.354761            3.354761\n",
       "38                 O-H-Encoding__month_9     3.086679            3.086679\n",
       "36                 O-H-Encoding__month_7     2.336287            2.336287\n",
       "10                  O-H-Encoding__hour_4    -2.196889            2.196889\n",
       "32                 O-H-Encoding__month_3     2.087444            2.087444\n",
       "25                 O-H-Encoding__hour_19    -1.985795            1.985795\n",
       "22                 O-H-Encoding__hour_16     1.746832            1.746832\n",
       "4                 O-H-Encoding__season_3    -1.674755            1.674755\n",
       "30                 O-H-Encoding__month_1    -0.814373            0.814373\n",
       "6                   O-H-Encoding__hour_0    -0.303561            0.303561\n",
       "28                 O-H-Encoding__hour_22    -0.301442            0.301442\n",
       "27                 O-H-Encoding__hour_21    -0.257575            0.257575\n",
       "26                 O-H-Encoding__hour_20    -0.252140            0.252140\n",
       "5                 O-H-Encoding__season_4     0.037050            0.037050\n",
       "8                   O-H-Encoding__hour_2     0.000000            0.000000\n",
       "7                   O-H-Encoding__hour_1    -0.000000            0.000000\n",
       "1   O-H-Encoding__Weather Model_NCEP GFS    -0.000000            0.000000\n",
       "9                   O-H-Encoding__hour_3    -0.000000            0.000000\n",
       "13                  O-H-Encoding__hour_7     0.000000            0.000000\n",
       "29                 O-H-Encoding__hour_23     0.000000            0.000000\n",
       "35                 O-H-Encoding__month_6    -0.000000            0.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten Linearen Regressor aus GridSearchCV\n",
    "best_lasso_model = pipe_lasso.named_steps[\"gs_lasso\"].best_estimator_\n",
    "\n",
    "# Abrufe der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_lasso.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Koeffizienten\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": best_lasso_model.coef_\n",
    "})\n",
    "\n",
    "coefficients[\"Feature_Importance\"] = coefficients[\"Coefficient\"].abs()\n",
    "coefficients = coefficients.sort_values(by=\"Feature_Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der wichtigsten Features\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für den Entscheidungsbaum\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 5, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "RMSE: 59.68393968304205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\263203898.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\263203898.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test2[\"Solar_MWh_pred\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !Pipeline: DecisionTree Modell\n",
    "pipe_tree = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_tree\", GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_tree.named_steps[\"gs_tree\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_tree.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_tree.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_tree.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skalieren__SolarDownwardRadiation</td>\n",
       "      <td>0.981349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-H-Encoding__Weather Model_NCEP GFS</td>\n",
       "      <td>0.013140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O-H-Encoding__Weather Model_DWD ICON</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skalieren__CloudCover</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skalieren__Temperature</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Importance\n",
       "4     Skalieren__SolarDownwardRadiation    0.981349\n",
       "1  O-H-Encoding__Weather Model_NCEP GFS    0.013140\n",
       "0  O-H-Encoding__Weather Model_DWD ICON    0.003823\n",
       "2                 Skalieren__CloudCover    0.001687\n",
       "3                Skalieren__Temperature    0.000000"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_tree_model = pipe_tree.named_steps[\"gs_tree\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_tree.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_tree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 25}\n",
      "RMSE: 56.981187937646155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\2116397776.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
      "C:\\Users\\achim\\AppData\\Local\\Temp\\ipykernel_20600\\2116397776.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test2[\"Solar_MWh_pred\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter für Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 20, 25],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "# !Pipeline: Random Forest Modell\n",
    "pipe_rand_frst = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_rand_frst\", GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5))\n",
    "                       ])\n",
    "pipe_rand_frst.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_rand_frst.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_rmse = rmse\n",
    "old_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere den besten DecisionTreeRegressor aus GridSearchCV\n",
    "best_randtree_model = pipe_rand_frst.named_steps[\"gs_rand_frst\"].best_estimator_\n",
    "\n",
    "# Abrufen der Feature-Namen nach Vorverarbeitung\n",
    "feature_names = pipe_rand_frst.named_steps[\"Vorverarbeitung\"].get_feature_names_out()\n",
    "\n",
    "# Erstelle einen DataFrame mit den Feature Importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": best_randtree_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sortiere die Features nach ihrer Importance (absolut, um die wichtigsten Features zuerst zu sehen)\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "RMSE: 62.14068630900931\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter für Gradient Boosting\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "# !Pipeline: Gradient Boosting Modell\n",
    "pipe_grad_boost = Pipeline([(\"Vorverarbeitung\", vorverarbeitung),\n",
    "                       (\"gs_grad_boost\", GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid))\n",
    "                       ])\n",
    "pipe_grad_boost.fit(X_train, y_train)\n",
    "\n",
    "# Extrahiere das beste Modell und die besten Parameter\n",
    "best_params = pipe_grad_boost.named_steps[\"gs_grad_boost\"].best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "y_pred = pipe_grad_boost.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_pred = pipe_grad_boost.predict(df_merged_test1)\n",
    "df_merged_test1[\"Solar_MWh_pred\"] = y_pred\n",
    "y_pred = pipe_grad_boost.predict(df_merged_test2)\n",
    "df_merged_test2[\"Solar_MWh_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_test1.to_pickle('test1.pkl')\n",
    "df_merged_test2.to_pickle('test2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
